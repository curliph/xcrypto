% =============================================================================

\subsection{More specific,  low(er)-level points}
\label{appx:discuss:lo}

\begin{itemize}

\item Instruction mnemonics follow a (somewhat) consistent scheme; they
      all include a domain-separating prefix \VERB[RV]{xc}, and, where
      need be, a suffix intended to identify specific variants.  These 
      include
      \[
      \begin{array}{lcl}
      \VERB[RV]{i} &:& \mbox{immediate (vs. register)   } \\
      \VERB[RV]{u} &:& \mbox{updating  (vs. overwriting)} \\
      \VERB[RV]{b} &:& \mbox{    byte-oriented}           \\
      \VERB[RV]{h} &:& \mbox{halfword-oriented}           \\
      \VERB[RV]{w} &:& \mbox{    word-oriented}           \\
      \VERB[RV]{x} &:& \mbox{a size parameter}            \\
      \end{array}
      \]
\item Although they share a memory interface, there is no requirement for
      the host core and co-processor to share an address space.  Indeed,
      it is easy to imagine cases where using disjoint address spaces is
      useful; examples include use of
      a) an OTP-style memory for key storage, 
         or
      b) a (uncached) scratch-pad memory,
      by the co-processor alone.

% TODO
%\designnote{The RISC-V version of \ASM{LUI} is both for constant creation
%(in tandem with \ASM{ORI} and loading addresses.
%Since the zeroing of the low 12 bits by \ASM{LUI} is mainly useful 
%for addresses, we remove this functionality in favour of leaving the
%low half of the register unmodified.
%The rationale being that two instructions can still create and 32-bit
%immediate, but that if we know a register is zero to begin
%with, we can then use only one instruction to create masks which fit
%into only a single halfword.}

\item Per \REFSEC{sec:spec:instr:2:4}, 
      \VERB[RV]{xc.mix.l}
      and
      \VERB[RV]{xc.mix.h}
      use the immediate 
      $ 
      0 \leq \VERB[RV]{rtamt} < 16 
      $ 
      to right-rotate $\XCR[*][{\VERB[RV]{crs1}}]$ by $d$ bits where
      $0  \leq d < 16$
      and
      $16 \leq d < 32$
      respectivly.
      The specification of {\em two} instructions vs. {\em one} that can
      deal with 
      $0  \leq d < 32$
      is motivated by instruction encoding: it is easier to avoid having
      a dedicated $5$-bit immiediate field, reusing the existing $4$-bit
      field, e.g., as used by
      \VERB[RV]{xc.bop}.

%%%\designnote{
%%%    While it is of-course possible to emulate the {\tt .h} variants of
%%%    \ASM{SCATTER} and \ASM{GATHER} with the {\tt.b} variants, we felt that
%%%    the performance and efficency savings to be had from telling the hardware
%%%    explicitly to work on halfwords were worth the extra instructions.
%%%}
%%%An implementation may perform the memory accesses in any order. The instructions
%%%will raise address misalignment exceptions in line with how misalignment is
%%%handled in the rest of the ISA.
%%%If any of the memory accesses cause
%%%a {\em load access fault, load page fault, store page fault} or
%%%{\em store access fault} then the address of the access which caused the
%%%exception is written to the {\tt MTVAL} csr. The value taken by the
%%%destination register bytes should an exception occur at any point in the
%%%instruction is {\em implementation dependent}.
%%%
%%%Implementations may abort execution of \ASM{SCATTER} or \ASM{GATHER} part way
%%%though in order to service an interrupt. If the instructions are aborted
%%%early, the value taken by the destination register bytes is {\em
%%%implementation dependent}. The implementation is responsible for ensuring
%%%that the {\tt EPC} register is set appropriately depending on whether the
%%%interrupt is taken during, or at the end of, the instruction.
%%%\designnote{Implementation of these instructions should consider the impact of
%%%shared memory systems, since it will be possible for other agents in the
%%%system to access memory during the execution of this instruction. In systems
%%%possessing a cache, programmers must be mindful that these instructions
%%%can cause odd behaviour due to the non-linear access pattern the instruction
%%%creates.}

\end{itemize}

% =============================================================================

\subsection{More  generic, high(er)-level points}
\label{appx:discuss:hi}

\begin{itemize}

\item Lee and Fiskiran introduce (e.g., see~\cite{SCARV:LeeFis:05}) the PLX
      design, which, among other concepts, supports 
      a) sub-word parallelism (cf. packed, or SWAR-like operations),
         and
      b) word size scalability (or data-path scalability).
      First, 
      note that a fully sub-word parallel ISA is orthogonal wrt. all useful
      sub-word sizes; PLX supports $n$-byte sub-word sizes for sane $n$.
      Second,
      note that, in a sense, RISC-V is word size scalable: it can cater for
      implementations that, e.g., have a $32$-bit instructions but a $32$-,
      $64$-, or $128$-bit general-purpose register file (and address space).
      The same concept is useful wrt. the co-processor, and indeed, for the
      multi-precision operations
      (per \REFSEC{sec:spec:instr:2:5})
      in particular.

      The current design considers sub-{\em byte} (e.g., $4$-bit), sub-word
      sizes; doing so is motivated, e.g., by their utility in some classes 
      of light-weight block cipher.  However, it does not currently explore 
      the potential of a scalable word size: it assumes the general-purpose
      and co-processor register file word sizes are {\em both} $32$ bits.

\item Consider a general case, wherein a given ISA has instruction formats
      to allow access to $n$ general-purpose registers, st. 
      $
      n = s + d
      $ 
      for $s$ sources and $d$ destinations, meaning an associated encoding 
      must somehow specify $n$ register addresses.  The special case
      $
      n = 3 = 2 + 1 
      $
      is common, and adopted by RISC-V, but it should nevertheless be clear
      that {\em other} cases can also be useful.  A common ``wrinkle'' in a 
      strict $3$-address case is (full) $( w \times w )$-bit multiplication, 
      which produces a $(2 \cdot w )$-bit product and therefore demands use 
      of {\em two} $w$-bit destination registers.
   
      One of the strategies underlying \XCID is support for larger $s$ and
      $d$.  This is rationalised by a (ideally positive) trade-off between
      a) increased register file complexity, as a result of the requirement
         to support $n$ ports, or, alternatively, multi-cycle operations,
         vs.
      b) increased register file bandwidth.
      The latter enables each instruction to perform more, or richer forms 
      of computation, aligning well with the demands of many cryptographic 
      workloads: this essentially matches the concept
      Lee et al.~\cite{SCARV:LeeYanShi:04}
      describe as data-rich execution, supported, in their terminology, by 
      Multi-word Operands, Multi-word Results (MOMR)
      capable computational infrastructure.

      Even {\em if} said trade-off is acceptable, however, it also implies 
      some challenges wrt. instruction encoding.  There seem to be several 
      possible options:

      \begin{enumerate}
      \item One could make all  register addresses {\em explicit}.
            For example, XS1 uses a long (i.e., $32$-bit) $6$-address 
            instruction format~\cite[Page 246]{SCARV:XS1:09} 
            to encode
            {\tt lmul}~\cite[Page 146]{SCARV:XS1:09}.
      \item One could make some register addresses {\em implicit}.  
            For example, the x86 $( 32 \times 32 )$-bit multiplication 
            instruction 
            {\tt mul}~\cite[Page 4-144--4-145]{SCARV:X86:2:18} 
            makes implicit uses of {\tt edx} and {\tt edx} as destinations.
      \item One could make some register addresses {\em implied}.
            For example, this approach has been considered within the
            specific context of support fioryptography: 
            Lee and Choi~\cite{SCARV:LeeCho:08} propose Register File
            Extension for Multi-word and Long-word Operation (RFEMLO), 
            where a group of $n$ contiguous registers is identified by 
            one register address plus a group size (or level in their terminology): 
            address $i$ and level $n$ implies use of registers
            \[
            i, i + 1, i + 2, \ldots i + 2^n - 1 .
            \]
            Note that this approach potentially causes an issue wrt.
            registers with specific semantics.  For example, in many
            RISC-like ISAs (including RISC-V), $\GPR[0]$ is fixed to 
            $0$; it may be difficult to include or exclude $\GPR[0]$ 
            in a group as need be.
      \item One could make some register addresses {\em overloaded}.
            For example, ARMv7-A includes a so-called ``unsigned multiply,
            accumulate accumulate'' instruction 
            {\tt umaal}~\cite[Section A8.8.255]{SCARV:ARMv7_M:17} 
            whose format {\em suggests} $n = 4 = 2 + 2$ but in fact 
            reuses the two destination as additional sources.
      \end{enumerate}
      
      \noindent
      Note that several of these approaches have an implication for the
      difficulty of register allocation; the obvious example is that of
      implicit register addresses.  Likewise, there are various generic
      ways to mitigate the encoding pressure (i.e., the availability of 
      at most $w$ bits) given an approach.  For example one could
      
      \begin{enumerate}
      \item restrict access to some subset of the register file 
            (cf. ARM Thumb or RV32E) 
            thereby reducing the number of bits required to encode each  
            register address,
            or
      \item use some form of instruction prefix.
      \end{enumerate}
      
      \noindent
      The current design is somewhat conservative, in the sense it 
      a) supports (upto) $d = 2$ and $s = 3$, 
         optionally using implied specification option for destinations: 
         one register address is explicit and the other can be implied,
      b) can have short register addresses than normal, due to the use
         of a $16$-entry co-processor register file.
      It does not explore the potential for, and trade-offs wrt. larger 
      $d$ or $s$: doing so is demonstrably useful, but, equally implies
      a range of drawbacks (e.g., overhead wrt. co-processor register 
      file size, complexity in instruction en/decoding, requirement for
      multi-cycle instruction execution).

\end{itemize}

% =============================================================================
